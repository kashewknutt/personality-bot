{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 7741,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006459113809585325,
      "grad_norm": 1.0244420766830444,
      "learning_rate": 4.1379310344827587e-05,
      "loss": 6.8135,
      "step": 50
    },
    {
      "epoch": 0.01291822761917065,
      "grad_norm": 0.9067941308021545,
      "learning_rate": 8.448275862068966e-05,
      "loss": 4.3482,
      "step": 100
    },
    {
      "epoch": 0.019377341428755974,
      "grad_norm": 1.445799708366394,
      "learning_rate": 0.00012758620689655174,
      "loss": 3.9231,
      "step": 150
    },
    {
      "epoch": 0.0258364552383413,
      "grad_norm": 1.485850214958191,
      "learning_rate": 0.0001706896551724138,
      "loss": 3.6951,
      "step": 200
    },
    {
      "epoch": 0.032295569047926624,
      "grad_norm": 1.0481586456298828,
      "learning_rate": 0.00019957384471966974,
      "loss": 3.5671,
      "step": 250
    },
    {
      "epoch": 0.03875468285751195,
      "grad_norm": 1.0037972927093506,
      "learning_rate": 0.00019824210946863764,
      "loss": 3.5093,
      "step": 300
    },
    {
      "epoch": 0.045213796667097274,
      "grad_norm": 1.2120970487594604,
      "learning_rate": 0.00019691037421760554,
      "loss": 3.5466,
      "step": 350
    },
    {
      "epoch": 0.0516729104766826,
      "grad_norm": 1.2102142572402954,
      "learning_rate": 0.00019557863896657344,
      "loss": 3.3843,
      "step": 400
    },
    {
      "epoch": 0.05813202428626792,
      "grad_norm": 0.4853372275829315,
      "learning_rate": 0.00019424690371554136,
      "loss": 3.6105,
      "step": 450
    },
    {
      "epoch": 0.06459113809585325,
      "grad_norm": 0.9690330624580383,
      "learning_rate": 0.00019291516846450926,
      "loss": 3.4562,
      "step": 500
    },
    {
      "epoch": 0.07105025190543858,
      "grad_norm": 1.236877202987671,
      "learning_rate": 0.00019158343321347716,
      "loss": 3.4598,
      "step": 550
    },
    {
      "epoch": 0.0775093657150239,
      "grad_norm": 0.9161528944969177,
      "learning_rate": 0.0001902516979624451,
      "loss": 3.3156,
      "step": 600
    },
    {
      "epoch": 0.08396847952460923,
      "grad_norm": 1.135277509689331,
      "learning_rate": 0.000188919962711413,
      "loss": 3.4438,
      "step": 650
    },
    {
      "epoch": 0.09042759333419455,
      "grad_norm": 1.2051987648010254,
      "learning_rate": 0.0001875882274603809,
      "loss": 3.4379,
      "step": 700
    },
    {
      "epoch": 0.09688670714377988,
      "grad_norm": 0.8941709399223328,
      "learning_rate": 0.0001862564922093488,
      "loss": 3.3352,
      "step": 750
    },
    {
      "epoch": 0.1033458209533652,
      "grad_norm": 0.9688630104064941,
      "learning_rate": 0.0001849247569583167,
      "loss": 3.4822,
      "step": 800
    },
    {
      "epoch": 0.10980493476295053,
      "grad_norm": 0.6783671379089355,
      "learning_rate": 0.0001835930217072846,
      "loss": 3.2486,
      "step": 850
    },
    {
      "epoch": 0.11626404857253585,
      "grad_norm": 1.1314936876296997,
      "learning_rate": 0.0001822612864562525,
      "loss": 3.4848,
      "step": 900
    },
    {
      "epoch": 0.12272316238212118,
      "grad_norm": 0.7450606226921082,
      "learning_rate": 0.0001809295512052204,
      "loss": 3.2604,
      "step": 950
    },
    {
      "epoch": 0.1291822761917065,
      "grad_norm": 1.0635287761688232,
      "learning_rate": 0.0001795978159541883,
      "loss": 3.2946,
      "step": 1000
    },
    {
      "epoch": 0.13564139000129183,
      "grad_norm": 0.8072578310966492,
      "learning_rate": 0.0001782660807031562,
      "loss": 3.3954,
      "step": 1050
    },
    {
      "epoch": 0.14210050381087716,
      "grad_norm": 1.1562079191207886,
      "learning_rate": 0.00017693434545212414,
      "loss": 3.3833,
      "step": 1100
    },
    {
      "epoch": 0.14855961762046246,
      "grad_norm": 1.3627322912216187,
      "learning_rate": 0.00017560261020109204,
      "loss": 3.3946,
      "step": 1150
    },
    {
      "epoch": 0.1550187314300478,
      "grad_norm": 1.0240485668182373,
      "learning_rate": 0.00017427087495005994,
      "loss": 3.2865,
      "step": 1200
    },
    {
      "epoch": 0.16147784523963313,
      "grad_norm": 1.0039386749267578,
      "learning_rate": 0.00017293913969902784,
      "loss": 3.3533,
      "step": 1250
    },
    {
      "epoch": 0.16793695904921846,
      "grad_norm": 0.7103854417800903,
      "learning_rate": 0.00017160740444799574,
      "loss": 3.3207,
      "step": 1300
    },
    {
      "epoch": 0.17439607285880376,
      "grad_norm": 1.281679630279541,
      "learning_rate": 0.00017027566919696366,
      "loss": 3.4039,
      "step": 1350
    },
    {
      "epoch": 0.1808551866683891,
      "grad_norm": 1.269515037536621,
      "learning_rate": 0.00016894393394593156,
      "loss": 3.238,
      "step": 1400
    },
    {
      "epoch": 0.18731430047797443,
      "grad_norm": 0.5744706392288208,
      "learning_rate": 0.00016761219869489946,
      "loss": 3.212,
      "step": 1450
    },
    {
      "epoch": 0.19377341428755976,
      "grad_norm": 0.6206876635551453,
      "learning_rate": 0.00016628046344386736,
      "loss": 3.1889,
      "step": 1500
    },
    {
      "epoch": 0.20023252809714506,
      "grad_norm": 0.6747455596923828,
      "learning_rate": 0.00016494872819283526,
      "loss": 2.9888,
      "step": 1550
    },
    {
      "epoch": 0.2066916419067304,
      "grad_norm": 1.1012016534805298,
      "learning_rate": 0.00016361699294180316,
      "loss": 3.2069,
      "step": 1600
    },
    {
      "epoch": 0.21315075571631573,
      "grad_norm": 0.7947525382041931,
      "learning_rate": 0.0001622852576907711,
      "loss": 3.1752,
      "step": 1650
    },
    {
      "epoch": 0.21960986952590106,
      "grad_norm": 0.9719741940498352,
      "learning_rate": 0.000160953522439739,
      "loss": 3.3663,
      "step": 1700
    },
    {
      "epoch": 0.22606898333548636,
      "grad_norm": 0.5067399144172668,
      "learning_rate": 0.0001596217871887069,
      "loss": 3.2845,
      "step": 1750
    },
    {
      "epoch": 0.2325280971450717,
      "grad_norm": 1.1762815713882446,
      "learning_rate": 0.0001582900519376748,
      "loss": 3.3146,
      "step": 1800
    },
    {
      "epoch": 0.23898721095465703,
      "grad_norm": 0.9823411107063293,
      "learning_rate": 0.00015695831668664269,
      "loss": 3.285,
      "step": 1850
    },
    {
      "epoch": 0.24544632476424236,
      "grad_norm": 1.0573593378067017,
      "learning_rate": 0.0001556265814356106,
      "loss": 3.2039,
      "step": 1900
    },
    {
      "epoch": 0.2519054385738277,
      "grad_norm": 1.159865140914917,
      "learning_rate": 0.0001542948461845785,
      "loss": 3.2608,
      "step": 1950
    },
    {
      "epoch": 0.258364552383413,
      "grad_norm": 1.2190300226211548,
      "learning_rate": 0.00015296311093354644,
      "loss": 3.1489,
      "step": 2000
    },
    {
      "epoch": 0.2648236661929983,
      "grad_norm": 1.0714675188064575,
      "learning_rate": 0.00015163137568251434,
      "loss": 3.238,
      "step": 2050
    },
    {
      "epoch": 0.27128278000258366,
      "grad_norm": 0.9940062165260315,
      "learning_rate": 0.00015029964043148224,
      "loss": 3.2387,
      "step": 2100
    },
    {
      "epoch": 0.27774189381216896,
      "grad_norm": 1.0573439598083496,
      "learning_rate": 0.00014896790518045014,
      "loss": 3.2493,
      "step": 2150
    },
    {
      "epoch": 0.2842010076217543,
      "grad_norm": 0.6264817118644714,
      "learning_rate": 0.00014763616992941804,
      "loss": 3.2352,
      "step": 2200
    },
    {
      "epoch": 0.2906601214313396,
      "grad_norm": 1.0159530639648438,
      "learning_rate": 0.00014630443467838594,
      "loss": 3.2624,
      "step": 2250
    },
    {
      "epoch": 0.29711923524092493,
      "grad_norm": 0.8373890519142151,
      "learning_rate": 0.00014497269942735386,
      "loss": 3.1627,
      "step": 2300
    },
    {
      "epoch": 0.3035783490505103,
      "grad_norm": 0.5701760649681091,
      "learning_rate": 0.00014364096417632176,
      "loss": 3.0558,
      "step": 2350
    },
    {
      "epoch": 0.3100374628600956,
      "grad_norm": 1.4779152870178223,
      "learning_rate": 0.00014230922892528966,
      "loss": 3.1344,
      "step": 2400
    },
    {
      "epoch": 0.3164965766696809,
      "grad_norm": 1.0247671604156494,
      "learning_rate": 0.00014097749367425756,
      "loss": 3.1676,
      "step": 2450
    },
    {
      "epoch": 0.32295569047926626,
      "grad_norm": 0.8475361466407776,
      "learning_rate": 0.00013964575842322546,
      "loss": 3.0784,
      "step": 2500
    },
    {
      "epoch": 0.32941480428885156,
      "grad_norm": 0.818080723285675,
      "learning_rate": 0.00013831402317219336,
      "loss": 3.109,
      "step": 2550
    },
    {
      "epoch": 0.3358739180984369,
      "grad_norm": 1.0057475566864014,
      "learning_rate": 0.0001369822879211613,
      "loss": 3.2476,
      "step": 2600
    },
    {
      "epoch": 0.3423330319080222,
      "grad_norm": 0.7273865938186646,
      "learning_rate": 0.0001356505526701292,
      "loss": 3.1667,
      "step": 2650
    },
    {
      "epoch": 0.3487921457176075,
      "grad_norm": 0.5156862139701843,
      "learning_rate": 0.0001343188174190971,
      "loss": 3.2379,
      "step": 2700
    },
    {
      "epoch": 0.3552512595271929,
      "grad_norm": 1.170352578163147,
      "learning_rate": 0.000132987082168065,
      "loss": 3.1288,
      "step": 2750
    },
    {
      "epoch": 0.3617103733367782,
      "grad_norm": 1.1601462364196777,
      "learning_rate": 0.0001316553469170329,
      "loss": 3.199,
      "step": 2800
    },
    {
      "epoch": 0.3681694871463635,
      "grad_norm": 0.9187342524528503,
      "learning_rate": 0.0001303236116660008,
      "loss": 3.1696,
      "step": 2850
    },
    {
      "epoch": 0.37462860095594885,
      "grad_norm": 1.3656508922576904,
      "learning_rate": 0.00012899187641496871,
      "loss": 3.1841,
      "step": 2900
    },
    {
      "epoch": 0.38108771476553416,
      "grad_norm": 0.6135057210922241,
      "learning_rate": 0.0001276601411639366,
      "loss": 3.1272,
      "step": 2950
    },
    {
      "epoch": 0.3875468285751195,
      "grad_norm": 1.1322073936462402,
      "learning_rate": 0.0001263284059129045,
      "loss": 3.1678,
      "step": 3000
    },
    {
      "epoch": 0.3940059423847048,
      "grad_norm": 0.5506979823112488,
      "learning_rate": 0.0001249966706618724,
      "loss": 3.1118,
      "step": 3050
    },
    {
      "epoch": 0.4004650561942901,
      "grad_norm": 0.6803639531135559,
      "learning_rate": 0.0001236649354108403,
      "loss": 3.1864,
      "step": 3100
    },
    {
      "epoch": 0.4069241700038755,
      "grad_norm": 0.8700271248817444,
      "learning_rate": 0.00012233320015980824,
      "loss": 3.2028,
      "step": 3150
    },
    {
      "epoch": 0.4133832838134608,
      "grad_norm": 0.8239033818244934,
      "learning_rate": 0.00012100146490877615,
      "loss": 3.2078,
      "step": 3200
    },
    {
      "epoch": 0.4198423976230461,
      "grad_norm": 0.4534784257411957,
      "learning_rate": 0.00011966972965774405,
      "loss": 3.0298,
      "step": 3250
    },
    {
      "epoch": 0.42630151143263145,
      "grad_norm": 0.8277280330657959,
      "learning_rate": 0.00011833799440671196,
      "loss": 3.1653,
      "step": 3300
    },
    {
      "epoch": 0.43276062524221676,
      "grad_norm": 0.9553802013397217,
      "learning_rate": 0.00011700625915567986,
      "loss": 3.3262,
      "step": 3350
    },
    {
      "epoch": 0.4392197390518021,
      "grad_norm": 1.3341213464736938,
      "learning_rate": 0.00011567452390464776,
      "loss": 3.0952,
      "step": 3400
    },
    {
      "epoch": 0.4456788528613874,
      "grad_norm": 0.9019103050231934,
      "learning_rate": 0.00011434278865361568,
      "loss": 3.1498,
      "step": 3450
    },
    {
      "epoch": 0.4521379666709727,
      "grad_norm": 1.112654209136963,
      "learning_rate": 0.00011301105340258358,
      "loss": 3.0397,
      "step": 3500
    },
    {
      "epoch": 0.4585970804805581,
      "grad_norm": 0.5748612284660339,
      "learning_rate": 0.00011167931815155148,
      "loss": 3.0392,
      "step": 3550
    },
    {
      "epoch": 0.4650561942901434,
      "grad_norm": 0.8768776059150696,
      "learning_rate": 0.00011034758290051939,
      "loss": 3.1599,
      "step": 3600
    },
    {
      "epoch": 0.4715153080997287,
      "grad_norm": 0.8662275671958923,
      "learning_rate": 0.00010901584764948729,
      "loss": 3.0535,
      "step": 3650
    },
    {
      "epoch": 0.47797442190931405,
      "grad_norm": 0.9513979554176331,
      "learning_rate": 0.00010768411239845519,
      "loss": 3.1287,
      "step": 3700
    },
    {
      "epoch": 0.48443353571889936,
      "grad_norm": 0.8786933422088623,
      "learning_rate": 0.0001063523771474231,
      "loss": 3.0439,
      "step": 3750
    },
    {
      "epoch": 0.4908926495284847,
      "grad_norm": 0.6868436336517334,
      "learning_rate": 0.000105020641896391,
      "loss": 3.0381,
      "step": 3800
    },
    {
      "epoch": 0.49735176333807,
      "grad_norm": 1.27338445186615,
      "learning_rate": 0.0001036889066453589,
      "loss": 3.115,
      "step": 3850
    },
    {
      "epoch": 0.5038108771476554,
      "grad_norm": 1.2128452062606812,
      "learning_rate": 0.00010235717139432681,
      "loss": 3.156,
      "step": 3900
    },
    {
      "epoch": 0.5102699909572407,
      "grad_norm": 0.8607093095779419,
      "learning_rate": 0.00010102543614329471,
      "loss": 3.2946,
      "step": 3950
    },
    {
      "epoch": 0.516729104766826,
      "grad_norm": 1.2929584980010986,
      "learning_rate": 9.969370089226263e-05,
      "loss": 3.1051,
      "step": 4000
    },
    {
      "epoch": 0.5231882185764113,
      "grad_norm": 0.9463637471199036,
      "learning_rate": 9.836196564123053e-05,
      "loss": 3.0977,
      "step": 4050
    },
    {
      "epoch": 0.5296473323859966,
      "grad_norm": 1.5571998357772827,
      "learning_rate": 9.703023039019843e-05,
      "loss": 3.0874,
      "step": 4100
    },
    {
      "epoch": 0.536106446195582,
      "grad_norm": 0.9772265553474426,
      "learning_rate": 9.569849513916634e-05,
      "loss": 2.9373,
      "step": 4150
    },
    {
      "epoch": 0.5425655600051673,
      "grad_norm": 0.9718537330627441,
      "learning_rate": 9.436675988813425e-05,
      "loss": 2.9852,
      "step": 4200
    },
    {
      "epoch": 0.5490246738147526,
      "grad_norm": 0.8699455261230469,
      "learning_rate": 9.303502463710215e-05,
      "loss": 3.1002,
      "step": 4250
    },
    {
      "epoch": 0.5554837876243379,
      "grad_norm": 0.9766964316368103,
      "learning_rate": 9.172992409109069e-05,
      "loss": 3.1927,
      "step": 4300
    },
    {
      "epoch": 0.5619429014339232,
      "grad_norm": 0.3869782090187073,
      "learning_rate": 9.039818884005859e-05,
      "loss": 3.0247,
      "step": 4350
    },
    {
      "epoch": 0.5684020152435086,
      "grad_norm": 1.1103955507278442,
      "learning_rate": 8.90664535890265e-05,
      "loss": 2.9845,
      "step": 4400
    },
    {
      "epoch": 0.5748611290530939,
      "grad_norm": 0.5598966479301453,
      "learning_rate": 8.773471833799442e-05,
      "loss": 3.1332,
      "step": 4450
    },
    {
      "epoch": 0.5813202428626792,
      "grad_norm": 0.7799640893936157,
      "learning_rate": 8.640298308696232e-05,
      "loss": 3.1816,
      "step": 4500
    },
    {
      "epoch": 0.5877793566722646,
      "grad_norm": 0.40259626507759094,
      "learning_rate": 8.507124783593022e-05,
      "loss": 3.0636,
      "step": 4550
    },
    {
      "epoch": 0.5942384704818499,
      "grad_norm": 1.0925025939941406,
      "learning_rate": 8.373951258489813e-05,
      "loss": 3.2748,
      "step": 4600
    },
    {
      "epoch": 0.6006975842914352,
      "grad_norm": 0.7854881286621094,
      "learning_rate": 8.240777733386603e-05,
      "loss": 3.0058,
      "step": 4650
    },
    {
      "epoch": 0.6071566981010206,
      "grad_norm": 1.476621150970459,
      "learning_rate": 8.107604208283393e-05,
      "loss": 3.0547,
      "step": 4700
    },
    {
      "epoch": 0.6136158119106059,
      "grad_norm": 1.0774568319320679,
      "learning_rate": 7.974430683180184e-05,
      "loss": 3.11,
      "step": 4750
    },
    {
      "epoch": 0.6200749257201912,
      "grad_norm": 1.0931285619735718,
      "learning_rate": 7.841257158076974e-05,
      "loss": 3.0718,
      "step": 4800
    },
    {
      "epoch": 0.6265340395297765,
      "grad_norm": 0.8084542155265808,
      "learning_rate": 7.708083632973766e-05,
      "loss": 3.0666,
      "step": 4850
    },
    {
      "epoch": 0.6329931533393618,
      "grad_norm": 1.2389343976974487,
      "learning_rate": 7.574910107870555e-05,
      "loss": 3.0056,
      "step": 4900
    },
    {
      "epoch": 0.6394522671489472,
      "grad_norm": 0.848139226436615,
      "learning_rate": 7.441736582767345e-05,
      "loss": 2.9831,
      "step": 4950
    },
    {
      "epoch": 0.6459113809585325,
      "grad_norm": 0.771841824054718,
      "learning_rate": 7.308563057664137e-05,
      "loss": 3.0187,
      "step": 5000
    },
    {
      "epoch": 0.6523704947681178,
      "grad_norm": 0.5342665910720825,
      "learning_rate": 7.175389532560928e-05,
      "loss": 3.2114,
      "step": 5050
    },
    {
      "epoch": 0.6588296085777031,
      "grad_norm": 1.3170995712280273,
      "learning_rate": 7.042216007457718e-05,
      "loss": 3.1462,
      "step": 5100
    },
    {
      "epoch": 0.6652887223872884,
      "grad_norm": 0.9050273299217224,
      "learning_rate": 6.909042482354508e-05,
      "loss": 3.1192,
      "step": 5150
    },
    {
      "epoch": 0.6717478361968738,
      "grad_norm": 0.9504335522651672,
      "learning_rate": 6.7758689572513e-05,
      "loss": 2.8838,
      "step": 5200
    },
    {
      "epoch": 0.6782069500064591,
      "grad_norm": 0.8159723281860352,
      "learning_rate": 6.642695432148089e-05,
      "loss": 3.1434,
      "step": 5250
    },
    {
      "epoch": 0.6846660638160444,
      "grad_norm": 1.0341206789016724,
      "learning_rate": 6.509521907044879e-05,
      "loss": 2.9528,
      "step": 5300
    },
    {
      "epoch": 0.6911251776256297,
      "grad_norm": 0.9291864633560181,
      "learning_rate": 6.37634838194167e-05,
      "loss": 2.9144,
      "step": 5350
    },
    {
      "epoch": 0.697584291435215,
      "grad_norm": 0.702786386013031,
      "learning_rate": 6.24317485683846e-05,
      "loss": 2.9151,
      "step": 5400
    },
    {
      "epoch": 0.7040434052448005,
      "grad_norm": 0.7858638763427734,
      "learning_rate": 6.11000133173525e-05,
      "loss": 2.9668,
      "step": 5450
    },
    {
      "epoch": 0.7105025190543858,
      "grad_norm": 0.7033451795578003,
      "learning_rate": 5.976827806632042e-05,
      "loss": 3.0795,
      "step": 5500
    },
    {
      "epoch": 0.7169616328639711,
      "grad_norm": 1.0086338520050049,
      "learning_rate": 5.843654281528832e-05,
      "loss": 3.1268,
      "step": 5550
    },
    {
      "epoch": 0.7234207466735564,
      "grad_norm": 1.0279725790023804,
      "learning_rate": 5.7104807564256224e-05,
      "loss": 2.8755,
      "step": 5600
    },
    {
      "epoch": 0.7298798604831417,
      "grad_norm": 1.0037873983383179,
      "learning_rate": 5.577307231322413e-05,
      "loss": 3.0778,
      "step": 5650
    },
    {
      "epoch": 0.736338974292727,
      "grad_norm": 1.049023985862732,
      "learning_rate": 5.4441337062192044e-05,
      "loss": 2.9769,
      "step": 5700
    },
    {
      "epoch": 0.7427980881023124,
      "grad_norm": 0.9048131704330444,
      "learning_rate": 5.310960181115995e-05,
      "loss": 3.0487,
      "step": 5750
    },
    {
      "epoch": 0.7492572019118977,
      "grad_norm": 1.0924137830734253,
      "learning_rate": 5.177786656012785e-05,
      "loss": 3.0603,
      "step": 5800
    },
    {
      "epoch": 0.755716315721483,
      "grad_norm": 0.5830045342445374,
      "learning_rate": 5.0446131309095756e-05,
      "loss": 3.0927,
      "step": 5850
    },
    {
      "epoch": 0.7621754295310683,
      "grad_norm": 1.0294594764709473,
      "learning_rate": 4.911439605806366e-05,
      "loss": 2.9543,
      "step": 5900
    },
    {
      "epoch": 0.7686345433406536,
      "grad_norm": 0.7715029716491699,
      "learning_rate": 4.778266080703156e-05,
      "loss": 2.9081,
      "step": 5950
    },
    {
      "epoch": 0.775093657150239,
      "grad_norm": 0.9345786571502686,
      "learning_rate": 4.645092555599947e-05,
      "loss": 3.054,
      "step": 6000
    },
    {
      "epoch": 0.7815527709598243,
      "grad_norm": 1.085037112236023,
      "learning_rate": 4.5119190304967375e-05,
      "loss": 2.9667,
      "step": 6050
    },
    {
      "epoch": 0.7880118847694096,
      "grad_norm": 0.8265213966369629,
      "learning_rate": 4.378745505393528e-05,
      "loss": 3.1136,
      "step": 6100
    },
    {
      "epoch": 0.794470998578995,
      "grad_norm": 1.1760305166244507,
      "learning_rate": 4.245571980290318e-05,
      "loss": 2.8849,
      "step": 6150
    },
    {
      "epoch": 0.8009301123885803,
      "grad_norm": 0.7134281396865845,
      "learning_rate": 4.1123984551871094e-05,
      "loss": 2.9463,
      "step": 6200
    },
    {
      "epoch": 0.8073892261981657,
      "grad_norm": 1.0832737684249878,
      "learning_rate": 3.979224930083899e-05,
      "loss": 3.0949,
      "step": 6250
    },
    {
      "epoch": 0.813848340007751,
      "grad_norm": 1.1173392534255981,
      "learning_rate": 3.84605140498069e-05,
      "loss": 3.0406,
      "step": 6300
    },
    {
      "epoch": 0.8203074538173363,
      "grad_norm": 0.815254807472229,
      "learning_rate": 3.7128778798774806e-05,
      "loss": 3.1021,
      "step": 6350
    },
    {
      "epoch": 0.8267665676269216,
      "grad_norm": 1.179726004600525,
      "learning_rate": 3.5797043547742706e-05,
      "loss": 2.9642,
      "step": 6400
    },
    {
      "epoch": 0.8332256814365069,
      "grad_norm": 0.47055715322494507,
      "learning_rate": 3.446530829671061e-05,
      "loss": 3.0304,
      "step": 6450
    },
    {
      "epoch": 0.8396847952460922,
      "grad_norm": 0.6876357793807983,
      "learning_rate": 3.3133573045678525e-05,
      "loss": 3.0084,
      "step": 6500
    },
    {
      "epoch": 0.8461439090556776,
      "grad_norm": 0.7470181584358215,
      "learning_rate": 3.1801837794646425e-05,
      "loss": 2.9457,
      "step": 6550
    },
    {
      "epoch": 0.8526030228652629,
      "grad_norm": 0.6776642799377441,
      "learning_rate": 3.047010254361433e-05,
      "loss": 2.9291,
      "step": 6600
    },
    {
      "epoch": 0.8590621366748482,
      "grad_norm": 1.3254755735397339,
      "learning_rate": 2.9138367292582238e-05,
      "loss": 2.9823,
      "step": 6650
    },
    {
      "epoch": 0.8655212504844335,
      "grad_norm": 0.9240157008171082,
      "learning_rate": 2.780663204155014e-05,
      "loss": 3.0772,
      "step": 6700
    },
    {
      "epoch": 0.8719803642940188,
      "grad_norm": 1.2176923751831055,
      "learning_rate": 2.6474896790518044e-05,
      "loss": 3.0531,
      "step": 6750
    },
    {
      "epoch": 0.8784394781036042,
      "grad_norm": 0.5611357688903809,
      "learning_rate": 2.514316153948595e-05,
      "loss": 3.059,
      "step": 6800
    },
    {
      "epoch": 0.8848985919131895,
      "grad_norm": 0.9515475630760193,
      "learning_rate": 2.3811426288453856e-05,
      "loss": 3.0719,
      "step": 6850
    },
    {
      "epoch": 0.8913577057227748,
      "grad_norm": 0.9822493195533752,
      "learning_rate": 2.2479691037421763e-05,
      "loss": 2.9137,
      "step": 6900
    },
    {
      "epoch": 0.8978168195323601,
      "grad_norm": 0.9933911561965942,
      "learning_rate": 2.1147955786389666e-05,
      "loss": 3.0084,
      "step": 6950
    },
    {
      "epoch": 0.9042759333419454,
      "grad_norm": 0.8199959397315979,
      "learning_rate": 1.9816220535357572e-05,
      "loss": 3.1443,
      "step": 7000
    },
    {
      "epoch": 0.9107350471515309,
      "grad_norm": 1.0234822034835815,
      "learning_rate": 1.8484485284325475e-05,
      "loss": 2.9322,
      "step": 7050
    },
    {
      "epoch": 0.9171941609611162,
      "grad_norm": 1.2601410150527954,
      "learning_rate": 1.715275003329338e-05,
      "loss": 3.1003,
      "step": 7100
    },
    {
      "epoch": 0.9236532747707015,
      "grad_norm": 0.5585875511169434,
      "learning_rate": 1.5821014782261288e-05,
      "loss": 3.0198,
      "step": 7150
    },
    {
      "epoch": 0.9301123885802868,
      "grad_norm": 0.477358877658844,
      "learning_rate": 1.4489279531229191e-05,
      "loss": 3.0586,
      "step": 7200
    },
    {
      "epoch": 0.9365715023898721,
      "grad_norm": 1.0948033332824707,
      "learning_rate": 1.3157544280197099e-05,
      "loss": 3.0587,
      "step": 7250
    },
    {
      "epoch": 0.9430306161994574,
      "grad_norm": 1.0806225538253784,
      "learning_rate": 1.1825809029165002e-05,
      "loss": 3.1209,
      "step": 7300
    },
    {
      "epoch": 0.9494897300090428,
      "grad_norm": 0.6461149454116821,
      "learning_rate": 1.0494073778132908e-05,
      "loss": 3.1063,
      "step": 7350
    },
    {
      "epoch": 0.9559488438186281,
      "grad_norm": 1.1674439907073975,
      "learning_rate": 9.162338527100813e-06,
      "loss": 3.0639,
      "step": 7400
    },
    {
      "epoch": 0.9624079576282134,
      "grad_norm": 1.0735175609588623,
      "learning_rate": 7.830603276068718e-06,
      "loss": 3.0539,
      "step": 7450
    },
    {
      "epoch": 0.9688670714377987,
      "grad_norm": 1.1472926139831543,
      "learning_rate": 6.498868025036622e-06,
      "loss": 3.0183,
      "step": 7500
    },
    {
      "epoch": 0.975326185247384,
      "grad_norm": 1.1438794136047363,
      "learning_rate": 5.167132774004528e-06,
      "loss": 3.0668,
      "step": 7550
    },
    {
      "epoch": 0.9817852990569694,
      "grad_norm": 1.1755924224853516,
      "learning_rate": 3.835397522972433e-06,
      "loss": 3.0292,
      "step": 7600
    },
    {
      "epoch": 0.9882444128665547,
      "grad_norm": 0.7345180511474609,
      "learning_rate": 2.503662271940338e-06,
      "loss": 3.1134,
      "step": 7650
    },
    {
      "epoch": 0.99470352667614,
      "grad_norm": 0.6771230697631836,
      "learning_rate": 1.1719270209082435e-06,
      "loss": 3.0018,
      "step": 7700
    }
  ],
  "logging_steps": 50,
  "max_steps": 7741,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.155263969943552e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}

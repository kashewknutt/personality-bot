{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 7741,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006459113809585325,
      "grad_norm": 6.943728923797607,
      "learning_rate": 3.53448275862069e-05,
      "loss": 7.6482,
      "step": 50
    },
    {
      "epoch": 0.01291822761917065,
      "grad_norm": 1.436841607093811,
      "learning_rate": 7.844827586206897e-05,
      "loss": 2.3099,
      "step": 100
    },
    {
      "epoch": 0.019377341428755974,
      "grad_norm": 0.08178231865167618,
      "learning_rate": 0.00012155172413793103,
      "loss": 0.3984,
      "step": 150
    },
    {
      "epoch": 0.0258364552383413,
      "grad_norm": 0.015627946704626083,
      "learning_rate": 0.0001646551724137931,
      "loss": 0.0926,
      "step": 200
    },
    {
      "epoch": 0.032295569047926624,
      "grad_norm": 0.25460654497146606,
      "learning_rate": 0.00019976028765481422,
      "loss": 0.097,
      "step": 250
    },
    {
      "epoch": 0.03875468285751195,
      "grad_norm": 0.24069440364837646,
      "learning_rate": 0.00019842855240378212,
      "loss": 0.0447,
      "step": 300
    },
    {
      "epoch": 0.045213796667097274,
      "grad_norm": 0.04739153012633324,
      "learning_rate": 0.00019709681715275005,
      "loss": 0.0191,
      "step": 350
    },
    {
      "epoch": 0.0516729104766826,
      "grad_norm": 0.029292110353708267,
      "learning_rate": 0.00019576508190171794,
      "loss": 0.0341,
      "step": 400
    },
    {
      "epoch": 0.05813202428626792,
      "grad_norm": 0.26332396268844604,
      "learning_rate": 0.00019443334665068584,
      "loss": 0.036,
      "step": 450
    },
    {
      "epoch": 0.06459113809585325,
      "grad_norm": 0.006954895798116922,
      "learning_rate": 0.00019310161139965374,
      "loss": 0.0033,
      "step": 500
    },
    {
      "epoch": 0.07105025190543858,
      "grad_norm": 0.006966161075979471,
      "learning_rate": 0.00019176987614862164,
      "loss": 0.0038,
      "step": 550
    },
    {
      "epoch": 0.0775093657150239,
      "grad_norm": 0.0003402887668926269,
      "learning_rate": 0.00019043814089758957,
      "loss": 0.0009,
      "step": 600
    },
    {
      "epoch": 0.08396847952460923,
      "grad_norm": 0.015809785574674606,
      "learning_rate": 0.00018910640564655747,
      "loss": 0.0005,
      "step": 650
    },
    {
      "epoch": 0.09042759333419455,
      "grad_norm": 0.0386078804731369,
      "learning_rate": 0.0001877746703955254,
      "loss": 0.0027,
      "step": 700
    },
    {
      "epoch": 0.09688670714377988,
      "grad_norm": 0.0016547064296901226,
      "learning_rate": 0.0001864429351444933,
      "loss": 0.0007,
      "step": 750
    },
    {
      "epoch": 0.1033458209533652,
      "grad_norm": 0.014221888035535812,
      "learning_rate": 0.0001851111998934612,
      "loss": 0.0003,
      "step": 800
    },
    {
      "epoch": 0.10980493476295053,
      "grad_norm": 0.00014006689889356494,
      "learning_rate": 0.0001837794646424291,
      "loss": 0.0031,
      "step": 850
    },
    {
      "epoch": 0.11626404857253585,
      "grad_norm": 0.003903359640389681,
      "learning_rate": 0.000182447729391397,
      "loss": 0.001,
      "step": 900
    },
    {
      "epoch": 0.12272316238212118,
      "grad_norm": 0.00166823691688478,
      "learning_rate": 0.00018111599414036492,
      "loss": 0.0021,
      "step": 950
    },
    {
      "epoch": 0.1291822761917065,
      "grad_norm": 0.002349019516259432,
      "learning_rate": 0.00017978425888933282,
      "loss": 0.0056,
      "step": 1000
    },
    {
      "epoch": 0.13564139000129183,
      "grad_norm": 0.001070148660801351,
      "learning_rate": 0.00017845252363830072,
      "loss": 0.0021,
      "step": 1050
    },
    {
      "epoch": 0.14210050381087716,
      "grad_norm": 0.0058706519193947315,
      "learning_rate": 0.00017712078838726862,
      "loss": 0.0024,
      "step": 1100
    },
    {
      "epoch": 0.14855961762046246,
      "grad_norm": 0.0010359847219660878,
      "learning_rate": 0.00017578905313623652,
      "loss": 0.0004,
      "step": 1150
    },
    {
      "epoch": 0.1550187314300478,
      "grad_norm": 0.0010204341961070895,
      "learning_rate": 0.00017445731788520442,
      "loss": 0.0006,
      "step": 1200
    },
    {
      "epoch": 0.16147784523963313,
      "grad_norm": 0.00042811784078367054,
      "learning_rate": 0.00017312558263417235,
      "loss": 0.0009,
      "step": 1250
    },
    {
      "epoch": 0.16793695904921846,
      "grad_norm": 0.004132983274757862,
      "learning_rate": 0.00017179384738314025,
      "loss": 0.0013,
      "step": 1300
    },
    {
      "epoch": 0.17439607285880376,
      "grad_norm": 9.568258246872574e-05,
      "learning_rate": 0.00017046211213210815,
      "loss": 0.0013,
      "step": 1350
    },
    {
      "epoch": 0.1808551866683891,
      "grad_norm": 0.0005025365389883518,
      "learning_rate": 0.00016913037688107605,
      "loss": 0.0004,
      "step": 1400
    },
    {
      "epoch": 0.18731430047797443,
      "grad_norm": 0.0001602502161404118,
      "learning_rate": 0.00016779864163004395,
      "loss": 0.0005,
      "step": 1450
    },
    {
      "epoch": 0.19377341428755976,
      "grad_norm": 0.0012501891469582915,
      "learning_rate": 0.00016646690637901184,
      "loss": 0.0012,
      "step": 1500
    },
    {
      "epoch": 0.20023252809714506,
      "grad_norm": 0.3215707838535309,
      "learning_rate": 0.00016513517112797977,
      "loss": 0.0045,
      "step": 1550
    },
    {
      "epoch": 0.2066916419067304,
      "grad_norm": 0.0015660931821912527,
      "learning_rate": 0.00016380343587694767,
      "loss": 0.0007,
      "step": 1600
    },
    {
      "epoch": 0.21315075571631573,
      "grad_norm": 0.052504997700452805,
      "learning_rate": 0.00016247170062591557,
      "loss": 0.0007,
      "step": 1650
    },
    {
      "epoch": 0.21960986952590106,
      "grad_norm": 0.0004149775777477771,
      "learning_rate": 0.00016113996537488347,
      "loss": 0.0002,
      "step": 1700
    },
    {
      "epoch": 0.22606898333548636,
      "grad_norm": 0.00024663953809067607,
      "learning_rate": 0.00015980823012385137,
      "loss": 0.0004,
      "step": 1750
    },
    {
      "epoch": 0.2325280971450717,
      "grad_norm": 0.0006765071302652359,
      "learning_rate": 0.00015847649487281927,
      "loss": 0.0012,
      "step": 1800
    },
    {
      "epoch": 0.23898721095465703,
      "grad_norm": 0.00037733439239673316,
      "learning_rate": 0.0001571447596217872,
      "loss": 0.0003,
      "step": 1850
    },
    {
      "epoch": 0.24544632476424236,
      "grad_norm": 0.0005015584174543619,
      "learning_rate": 0.00015581302437075512,
      "loss": 0.0001,
      "step": 1900
    },
    {
      "epoch": 0.2519054385738277,
      "grad_norm": 0.08383845537900925,
      "learning_rate": 0.00015448128911972302,
      "loss": 0.0001,
      "step": 1950
    },
    {
      "epoch": 0.258364552383413,
      "grad_norm": 0.0002441673423163593,
      "learning_rate": 0.00015314955386869092,
      "loss": 0.0002,
      "step": 2000
    },
    {
      "epoch": 0.2648236661929983,
      "grad_norm": 0.00041129012242890894,
      "learning_rate": 0.00015181781861765882,
      "loss": 0.0,
      "step": 2050
    },
    {
      "epoch": 0.27128278000258366,
      "grad_norm": 0.0010731639340519905,
      "learning_rate": 0.00015048608336662672,
      "loss": 0.0001,
      "step": 2100
    },
    {
      "epoch": 0.27774189381216896,
      "grad_norm": 0.005186188966035843,
      "learning_rate": 0.00014915434811559462,
      "loss": 0.0034,
      "step": 2150
    },
    {
      "epoch": 0.2842010076217543,
      "grad_norm": 0.00029233406530693173,
      "learning_rate": 0.00014782261286456255,
      "loss": 0.0004,
      "step": 2200
    },
    {
      "epoch": 0.2906601214313396,
      "grad_norm": 0.00837623979896307,
      "learning_rate": 0.00014649087761353045,
      "loss": 0.0014,
      "step": 2250
    },
    {
      "epoch": 0.29711923524092493,
      "grad_norm": 0.002872337121516466,
      "learning_rate": 0.00014515914236249835,
      "loss": 0.0007,
      "step": 2300
    },
    {
      "epoch": 0.3035783490505103,
      "grad_norm": 0.0013164053671061993,
      "learning_rate": 0.00014382740711146625,
      "loss": 0.0005,
      "step": 2350
    },
    {
      "epoch": 0.3100374628600956,
      "grad_norm": 4.551285383058712e-05,
      "learning_rate": 0.00014249567186043415,
      "loss": 0.0003,
      "step": 2400
    },
    {
      "epoch": 0.3164965766696809,
      "grad_norm": 0.4787675142288208,
      "learning_rate": 0.00014116393660940205,
      "loss": 0.0017,
      "step": 2450
    },
    {
      "epoch": 0.32295569047926626,
      "grad_norm": 0.0024266892578452826,
      "learning_rate": 0.00013983220135836997,
      "loss": 0.001,
      "step": 2500
    },
    {
      "epoch": 0.32941480428885156,
      "grad_norm": 1.0536773204803467,
      "learning_rate": 0.00013850046610733787,
      "loss": 0.0043,
      "step": 2550
    },
    {
      "epoch": 0.3358739180984369,
      "grad_norm": 0.008020982146263123,
      "learning_rate": 0.00013716873085630577,
      "loss": 0.0008,
      "step": 2600
    },
    {
      "epoch": 0.3423330319080222,
      "grad_norm": 0.005014786962419748,
      "learning_rate": 0.00013583699560527367,
      "loss": 0.0003,
      "step": 2650
    },
    {
      "epoch": 0.3487921457176075,
      "grad_norm": 0.0004520870861597359,
      "learning_rate": 0.00013450526035424157,
      "loss": 0.0003,
      "step": 2700
    },
    {
      "epoch": 0.3552512595271929,
      "grad_norm": 0.004839666653424501,
      "learning_rate": 0.0001331735251032095,
      "loss": 0.0032,
      "step": 2750
    },
    {
      "epoch": 0.3617103733367782,
      "grad_norm": 0.15517953038215637,
      "learning_rate": 0.0001318417898521774,
      "loss": 0.0031,
      "step": 2800
    },
    {
      "epoch": 0.3681694871463635,
      "grad_norm": 0.0004449722182471305,
      "learning_rate": 0.0001305100546011453,
      "loss": 0.0008,
      "step": 2850
    },
    {
      "epoch": 0.37462860095594885,
      "grad_norm": 0.0033839596435427666,
      "learning_rate": 0.0001291783193501132,
      "loss": 0.0002,
      "step": 2900
    },
    {
      "epoch": 0.38108771476553416,
      "grad_norm": 0.003416754538193345,
      "learning_rate": 0.0001278465840990811,
      "loss": 0.0003,
      "step": 2950
    },
    {
      "epoch": 0.3875468285751195,
      "grad_norm": 0.00018759335216600448,
      "learning_rate": 0.000126514848848049,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 0.3940059423847048,
      "grad_norm": 0.0031074455473572016,
      "learning_rate": 0.00012518311359701692,
      "loss": 0.0,
      "step": 3050
    },
    {
      "epoch": 0.4004650561942901,
      "grad_norm": 0.0003504697233438492,
      "learning_rate": 0.00012385137834598482,
      "loss": 0.0001,
      "step": 3100
    },
    {
      "epoch": 0.4069241700038755,
      "grad_norm": 0.00047930650180205703,
      "learning_rate": 0.00012251964309495272,
      "loss": 0.0003,
      "step": 3150
    },
    {
      "epoch": 0.4133832838134608,
      "grad_norm": 9.250357834389433e-05,
      "learning_rate": 0.00012118790784392065,
      "loss": 0.0,
      "step": 3200
    },
    {
      "epoch": 0.4198423976230461,
      "grad_norm": 0.0007765669724904001,
      "learning_rate": 0.00011985617259288855,
      "loss": 0.0001,
      "step": 3250
    },
    {
      "epoch": 0.42630151143263145,
      "grad_norm": 0.0002441931574139744,
      "learning_rate": 0.00011852443734185645,
      "loss": 0.0001,
      "step": 3300
    },
    {
      "epoch": 0.43276062524221676,
      "grad_norm": 0.00020515351206995547,
      "learning_rate": 0.00011719270209082436,
      "loss": 0.0,
      "step": 3350
    },
    {
      "epoch": 0.4392197390518021,
      "grad_norm": 0.008845190517604351,
      "learning_rate": 0.00011586096683979226,
      "loss": 0.0054,
      "step": 3400
    },
    {
      "epoch": 0.4456788528613874,
      "grad_norm": 0.00048454379430040717,
      "learning_rate": 0.00011452923158876016,
      "loss": 0.0006,
      "step": 3450
    },
    {
      "epoch": 0.4521379666709727,
      "grad_norm": 0.00010431209375383332,
      "learning_rate": 0.00011319749633772807,
      "loss": 0.0002,
      "step": 3500
    },
    {
      "epoch": 0.4585970804805581,
      "grad_norm": 0.017721356824040413,
      "learning_rate": 0.00011186576108669597,
      "loss": 0.0007,
      "step": 3550
    },
    {
      "epoch": 0.4650561942901434,
      "grad_norm": 0.004136393312364817,
      "learning_rate": 0.00011053402583566389,
      "loss": 0.0001,
      "step": 3600
    },
    {
      "epoch": 0.4715153080997287,
      "grad_norm": 0.0017656073905527592,
      "learning_rate": 0.00010920229058463179,
      "loss": 0.0001,
      "step": 3650
    },
    {
      "epoch": 0.47797442190931405,
      "grad_norm": 0.0008717481978237629,
      "learning_rate": 0.00010787055533359968,
      "loss": 0.001,
      "step": 3700
    },
    {
      "epoch": 0.48443353571889936,
      "grad_norm": 0.00040819350397214293,
      "learning_rate": 0.0001065388200825676,
      "loss": 0.0003,
      "step": 3750
    },
    {
      "epoch": 0.4908926495284847,
      "grad_norm": 0.00012998731108382344,
      "learning_rate": 0.0001052070848315355,
      "loss": 0.0013,
      "step": 3800
    },
    {
      "epoch": 0.49735176333807,
      "grad_norm": 0.0001278434065170586,
      "learning_rate": 0.0001038753495805034,
      "loss": 0.0001,
      "step": 3850
    },
    {
      "epoch": 0.5038108771476554,
      "grad_norm": 0.00011222893226658925,
      "learning_rate": 0.00010254361432947131,
      "loss": 0.0,
      "step": 3900
    },
    {
      "epoch": 0.5102699909572407,
      "grad_norm": 0.0001736399863148108,
      "learning_rate": 0.00010121187907843921,
      "loss": 0.0,
      "step": 3950
    },
    {
      "epoch": 0.516729104766826,
      "grad_norm": 8.79670333233662e-05,
      "learning_rate": 9.988014382740711e-05,
      "loss": 0.0,
      "step": 4000
    },
    {
      "epoch": 0.5231882185764113,
      "grad_norm": 0.00015652707952540368,
      "learning_rate": 9.854840857637502e-05,
      "loss": 0.0002,
      "step": 4050
    },
    {
      "epoch": 0.5296473323859966,
      "grad_norm": 9.769323514774442e-05,
      "learning_rate": 9.721667332534292e-05,
      "loss": 0.0002,
      "step": 4100
    },
    {
      "epoch": 0.536106446195582,
      "grad_norm": 5.884308120585047e-05,
      "learning_rate": 9.588493807431082e-05,
      "loss": 0.0001,
      "step": 4150
    },
    {
      "epoch": 0.5425655600051673,
      "grad_norm": 0.0005495533696375787,
      "learning_rate": 9.455320282327874e-05,
      "loss": 0.0,
      "step": 4200
    },
    {
      "epoch": 0.5490246738147526,
      "grad_norm": 4.6576398744946346e-05,
      "learning_rate": 9.322146757224665e-05,
      "loss": 0.0009,
      "step": 4250
    },
    {
      "epoch": 0.5554837876243379,
      "grad_norm": 0.00014536819071508944,
      "learning_rate": 9.188973232121455e-05,
      "loss": 0.0004,
      "step": 4300
    },
    {
      "epoch": 0.5619429014339232,
      "grad_norm": 0.00035581825068220496,
      "learning_rate": 9.055799707018246e-05,
      "loss": 0.0002,
      "step": 4350
    },
    {
      "epoch": 0.5684020152435086,
      "grad_norm": 0.00215736823156476,
      "learning_rate": 8.922626181915036e-05,
      "loss": 0.0005,
      "step": 4400
    },
    {
      "epoch": 0.5748611290530939,
      "grad_norm": 0.002597271464765072,
      "learning_rate": 8.789452656811826e-05,
      "loss": 0.0002,
      "step": 4450
    },
    {
      "epoch": 0.5813202428626792,
      "grad_norm": 0.00011330015695421025,
      "learning_rate": 8.656279131708617e-05,
      "loss": 0.0001,
      "step": 4500
    },
    {
      "epoch": 0.5877793566722646,
      "grad_norm": 0.004860593471676111,
      "learning_rate": 8.523105606605407e-05,
      "loss": 0.0003,
      "step": 4550
    },
    {
      "epoch": 0.5942384704818499,
      "grad_norm": 9.801641863305122e-05,
      "learning_rate": 8.389932081502197e-05,
      "loss": 0.0001,
      "step": 4600
    },
    {
      "epoch": 0.6006975842914352,
      "grad_norm": 2.0247947759344243e-05,
      "learning_rate": 8.256758556398989e-05,
      "loss": 0.0001,
      "step": 4650
    },
    {
      "epoch": 0.6071566981010206,
      "grad_norm": 8.014214836293831e-05,
      "learning_rate": 8.123585031295779e-05,
      "loss": 0.0005,
      "step": 4700
    },
    {
      "epoch": 0.6136158119106059,
      "grad_norm": 0.0002340529317734763,
      "learning_rate": 7.990411506192568e-05,
      "loss": 0.0,
      "step": 4750
    },
    {
      "epoch": 0.6200749257201912,
      "grad_norm": 0.00021436859969981015,
      "learning_rate": 7.85723798108936e-05,
      "loss": 0.0003,
      "step": 4800
    },
    {
      "epoch": 0.6265340395297765,
      "grad_norm": 0.00023892261378932744,
      "learning_rate": 7.724064455986151e-05,
      "loss": 0.0,
      "step": 4850
    },
    {
      "epoch": 0.6329931533393618,
      "grad_norm": 0.00030750338919460773,
      "learning_rate": 7.590890930882941e-05,
      "loss": 0.0,
      "step": 4900
    },
    {
      "epoch": 0.6394522671489472,
      "grad_norm": 0.00479108514264226,
      "learning_rate": 7.457717405779731e-05,
      "loss": 0.0,
      "step": 4950
    },
    {
      "epoch": 0.6459113809585325,
      "grad_norm": 1.1259818165854085e-05,
      "learning_rate": 7.324543880676522e-05,
      "loss": 0.0,
      "step": 5000
    },
    {
      "epoch": 0.6523704947681178,
      "grad_norm": 0.0010998984798789024,
      "learning_rate": 7.191370355573312e-05,
      "loss": 0.0,
      "step": 5050
    },
    {
      "epoch": 0.6588296085777031,
      "grad_norm": 3.457291313679889e-05,
      "learning_rate": 7.058196830470102e-05,
      "loss": 0.0001,
      "step": 5100
    },
    {
      "epoch": 0.6652887223872884,
      "grad_norm": 8.077624079305679e-05,
      "learning_rate": 6.925023305366894e-05,
      "loss": 0.0,
      "step": 5150
    },
    {
      "epoch": 0.6717478361968738,
      "grad_norm": 0.0005342295044101775,
      "learning_rate": 6.791849780263684e-05,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 0.6782069500064591,
      "grad_norm": 0.00022137528867460787,
      "learning_rate": 6.658676255160475e-05,
      "loss": 0.0,
      "step": 5250
    },
    {
      "epoch": 0.6846660638160444,
      "grad_norm": 0.00041911969310604036,
      "learning_rate": 6.525502730057265e-05,
      "loss": 0.0006,
      "step": 5300
    },
    {
      "epoch": 0.6911251776256297,
      "grad_norm": 9.259807484340854e-06,
      "learning_rate": 6.392329204954055e-05,
      "loss": 0.0,
      "step": 5350
    },
    {
      "epoch": 0.697584291435215,
      "grad_norm": 5.4024101700633764e-05,
      "learning_rate": 6.259155679850846e-05,
      "loss": 0.0006,
      "step": 5400
    },
    {
      "epoch": 0.7040434052448005,
      "grad_norm": 0.0002893221389967948,
      "learning_rate": 6.125982154747636e-05,
      "loss": 0.0,
      "step": 5450
    },
    {
      "epoch": 0.7105025190543858,
      "grad_norm": 0.00010791294334921986,
      "learning_rate": 5.9928086296444274e-05,
      "loss": 0.0001,
      "step": 5500
    },
    {
      "epoch": 0.7169616328639711,
      "grad_norm": 0.00013944438251201063,
      "learning_rate": 5.859635104541218e-05,
      "loss": 0.0001,
      "step": 5550
    },
    {
      "epoch": 0.7234207466735564,
      "grad_norm": 2.2400190573534928e-05,
      "learning_rate": 5.726461579438008e-05,
      "loss": 0.0,
      "step": 5600
    },
    {
      "epoch": 0.7298798604831417,
      "grad_norm": 2.970620153064374e-05,
      "learning_rate": 5.5932880543347986e-05,
      "loss": 0.0001,
      "step": 5650
    },
    {
      "epoch": 0.736338974292727,
      "grad_norm": 8.296618034364656e-05,
      "learning_rate": 5.460114529231589e-05,
      "loss": 0.0001,
      "step": 5700
    },
    {
      "epoch": 0.7427980881023124,
      "grad_norm": 3.447066410444677e-05,
      "learning_rate": 5.32694100412838e-05,
      "loss": 0.0,
      "step": 5750
    },
    {
      "epoch": 0.7492572019118977,
      "grad_norm": 0.00011778462794609368,
      "learning_rate": 5.19376747902517e-05,
      "loss": 0.0,
      "step": 5800
    },
    {
      "epoch": 0.755716315721483,
      "grad_norm": 9.728230907057878e-06,
      "learning_rate": 5.0605939539219605e-05,
      "loss": 0.0,
      "step": 5850
    },
    {
      "epoch": 0.7621754295310683,
      "grad_norm": 0.0027352655306458473,
      "learning_rate": 4.927420428818751e-05,
      "loss": 0.001,
      "step": 5900
    },
    {
      "epoch": 0.7686345433406536,
      "grad_norm": 0.0005740728811360896,
      "learning_rate": 4.794246903715541e-05,
      "loss": 0.0026,
      "step": 5950
    },
    {
      "epoch": 0.775093657150239,
      "grad_norm": 0.00027736095944419503,
      "learning_rate": 4.6610733786123324e-05,
      "loss": 0.0,
      "step": 6000
    },
    {
      "epoch": 0.7815527709598243,
      "grad_norm": 3.7785466702189296e-05,
      "learning_rate": 4.527899853509123e-05,
      "loss": 0.0001,
      "step": 6050
    },
    {
      "epoch": 0.7880118847694096,
      "grad_norm": 0.00028061948250979185,
      "learning_rate": 4.394726328405913e-05,
      "loss": 0.0004,
      "step": 6100
    },
    {
      "epoch": 0.794470998578995,
      "grad_norm": 0.0001164352215710096,
      "learning_rate": 4.2615528033027036e-05,
      "loss": 0.0001,
      "step": 6150
    },
    {
      "epoch": 0.8009301123885803,
      "grad_norm": 0.0009138820460066199,
      "learning_rate": 4.128379278199494e-05,
      "loss": 0.0007,
      "step": 6200
    },
    {
      "epoch": 0.8073892261981657,
      "grad_norm": 0.00018365439609624445,
      "learning_rate": 3.995205753096284e-05,
      "loss": 0.0001,
      "step": 6250
    },
    {
      "epoch": 0.813848340007751,
      "grad_norm": 4.08176492783241e-05,
      "learning_rate": 3.8620322279930756e-05,
      "loss": 0.0001,
      "step": 6300
    },
    {
      "epoch": 0.8203074538173363,
      "grad_norm": 3.147964525851421e-05,
      "learning_rate": 3.7288587028898655e-05,
      "loss": 0.0001,
      "step": 6350
    },
    {
      "epoch": 0.8267665676269216,
      "grad_norm": 0.0003196816542185843,
      "learning_rate": 3.595685177786656e-05,
      "loss": 0.0001,
      "step": 6400
    },
    {
      "epoch": 0.8332256814365069,
      "grad_norm": 0.00015246201655827463,
      "learning_rate": 3.462511652683447e-05,
      "loss": 0.0001,
      "step": 6450
    },
    {
      "epoch": 0.8396847952460922,
      "grad_norm": 4.475309106055647e-05,
      "learning_rate": 3.3293381275802374e-05,
      "loss": 0.0001,
      "step": 6500
    },
    {
      "epoch": 0.8461439090556776,
      "grad_norm": 0.00018705645925365388,
      "learning_rate": 3.1961646024770274e-05,
      "loss": 0.0,
      "step": 6550
    },
    {
      "epoch": 0.8526030228652629,
      "grad_norm": 6.816007226007059e-05,
      "learning_rate": 3.062991077373818e-05,
      "loss": 0.0,
      "step": 6600
    },
    {
      "epoch": 0.8590621366748482,
      "grad_norm": 2.2795731638325378e-05,
      "learning_rate": 2.929817552270609e-05,
      "loss": 0.0,
      "step": 6650
    },
    {
      "epoch": 0.8655212504844335,
      "grad_norm": 7.618749077664688e-05,
      "learning_rate": 2.7966440271673993e-05,
      "loss": 0.0,
      "step": 6700
    },
    {
      "epoch": 0.8719803642940188,
      "grad_norm": 2.4614473659312353e-05,
      "learning_rate": 2.66347050206419e-05,
      "loss": 0.0001,
      "step": 6750
    },
    {
      "epoch": 0.8784394781036042,
      "grad_norm": 0.00032982073025777936,
      "learning_rate": 2.5302969769609802e-05,
      "loss": 0.0,
      "step": 6800
    },
    {
      "epoch": 0.8848985919131895,
      "grad_norm": 3.0655264708912e-05,
      "learning_rate": 2.3971234518577705e-05,
      "loss": 0.0,
      "step": 6850
    },
    {
      "epoch": 0.8913577057227748,
      "grad_norm": 0.0002966500469483435,
      "learning_rate": 2.2639499267545615e-05,
      "loss": 0.0001,
      "step": 6900
    },
    {
      "epoch": 0.8978168195323601,
      "grad_norm": 0.0003318919916637242,
      "learning_rate": 2.1307764016513518e-05,
      "loss": 0.0,
      "step": 6950
    },
    {
      "epoch": 0.9042759333419454,
      "grad_norm": 0.009493892081081867,
      "learning_rate": 1.997602876548142e-05,
      "loss": 0.0,
      "step": 7000
    },
    {
      "epoch": 0.9107350471515309,
      "grad_norm": 0.00023048203729558736,
      "learning_rate": 1.8644293514449328e-05,
      "loss": 0.0,
      "step": 7050
    },
    {
      "epoch": 0.9171941609611162,
      "grad_norm": 0.0008610027143731713,
      "learning_rate": 1.7312558263417234e-05,
      "loss": 0.0,
      "step": 7100
    },
    {
      "epoch": 0.9236532747707015,
      "grad_norm": 0.00015090688248164952,
      "learning_rate": 1.5980823012385137e-05,
      "loss": 0.0,
      "step": 7150
    },
    {
      "epoch": 0.9301123885802868,
      "grad_norm": 5.289972614264116e-05,
      "learning_rate": 1.4649087761353045e-05,
      "loss": 0.0001,
      "step": 7200
    },
    {
      "epoch": 0.9365715023898721,
      "grad_norm": 6.216682231752202e-05,
      "learning_rate": 1.331735251032095e-05,
      "loss": 0.0001,
      "step": 7250
    },
    {
      "epoch": 0.9430306161994574,
      "grad_norm": 3.3296241781499702e-06,
      "learning_rate": 1.1985617259288853e-05,
      "loss": 0.0,
      "step": 7300
    },
    {
      "epoch": 0.9494897300090428,
      "grad_norm": 8.106681343633682e-05,
      "learning_rate": 1.0653882008256759e-05,
      "loss": 0.0,
      "step": 7350
    },
    {
      "epoch": 0.9559488438186281,
      "grad_norm": 2.4771357857389376e-05,
      "learning_rate": 9.322146757224664e-06,
      "loss": 0.0,
      "step": 7400
    },
    {
      "epoch": 0.9624079576282134,
      "grad_norm": 2.1301211745594628e-05,
      "learning_rate": 7.990411506192568e-06,
      "loss": 0.0,
      "step": 7450
    },
    {
      "epoch": 0.9688670714377987,
      "grad_norm": 7.671266212128103e-05,
      "learning_rate": 6.658676255160475e-06,
      "loss": 0.0,
      "step": 7500
    },
    {
      "epoch": 0.975326185247384,
      "grad_norm": 0.00011174011160619557,
      "learning_rate": 5.3269410041283796e-06,
      "loss": 0.0,
      "step": 7550
    },
    {
      "epoch": 0.9817852990569694,
      "grad_norm": 3.477146674413234e-05,
      "learning_rate": 3.995205753096284e-06,
      "loss": 0.0001,
      "step": 7600
    },
    {
      "epoch": 0.9882444128665547,
      "grad_norm": 3.999936325271847e-06,
      "learning_rate": 2.6634705020641898e-06,
      "loss": 0.0,
      "step": 7650
    },
    {
      "epoch": 0.99470352667614,
      "grad_norm": 0.00034443201730027795,
      "learning_rate": 1.3317352510320949e-06,
      "loss": 0.0,
      "step": 7700
    }
  ],
  "logging_steps": 50,
  "max_steps": 7741,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.155263969943552e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
